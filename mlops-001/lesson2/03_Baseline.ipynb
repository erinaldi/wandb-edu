{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/mlops-001/lesson1/03_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{course-lesson1} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723ae62-c55d-4c8f-9157-43c29189a2ff",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "<!--- @wandbcode{course-lesson1} -->\n",
    "\n",
    "In this notebook we will create a baseline solution to our semantic segmentation problem. To iterate fast a notebook is a handy solution. We will then refactor this code into a script to be able to use hyperparameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29116dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "\n",
    "import params\n",
    "from utils import get_predictions, create_iou_table, MIOU, BackgroundIOU, \\\n",
    "                  RoadIOU, TrafficLightIOU, TrafficSignIOU, PersonIOU, VehicleIOU, BicycleIOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0871e5-c07d-4a8b-817b-388c2e9bf7d1",
   "metadata": {},
   "source": [
    "Again, we're importing some global configuration parameters from `params.py` file. We have also defined some helper functions in `utils.py` - for example metrics we will track during our experiments.\n",
    "\n",
    "Let's now create a `train_config` that we'll pass to W&B `run` to control training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff6b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SimpleNamespace(\n",
    "    framework=\"fastai\",\n",
    "    img_size=(180, 320),\n",
    "    batch_size=8,\n",
    "    augment=True, # use data augmentation\n",
    "    epochs=10, \n",
    "    lr=2e-3,\n",
    "    pretrained=True,  # whether to use pretrained encoder\n",
    "    seed=42,  # for reproducibility\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38f014f3-d78f-4f5b-b038-d8020de43930",
   "metadata": {},
   "source": [
    "We are setting seed for reproducibility: this is a `fastai` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6765f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(train_config.seed, reproducible=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac2186cf",
   "metadata": {},
   "source": [
    "## Start run and get artifacts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e368b925",
   "metadata": {},
   "source": [
    "Initialize the `wandb` run: we pass the configuration we defined about for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32483e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33merinaldi\u001b[0m (\u001b[33merinaldi-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/enrythebest/Projects/wandb-edu/mlops-001/lesson1/wandb/run-20230215_170600-dz5gabr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/erinaldi-team/mlops-course-001/runs/dz5gabr2' target=\"_blank\">beaming-sweetheart-3</a></strong> to <a href='https://wandb.ai/erinaldi-team/mlops-course-001' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/erinaldi-team/mlops-course-001' target=\"_blank\">https://wandb.ai/erinaldi-team/mlops-course-001</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/erinaldi-team/mlops-course-001/runs/dz5gabr2' target=\"_blank\">https://wandb.ai/erinaldi-team/mlops-course-001/runs/dz5gabr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c1872-fc08-4304-9842-203d9ac45371",
   "metadata": {},
   "source": [
    "As usual, we will use W&B Artifacts to track the lineage of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df839467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bdd_simple_1k_split:latest, 846.07MB. 4010 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4010 of 4010 files downloaded.  \n",
      "Done. 0:0:1.2\n"
     ]
    }
   ],
   "source": [
    "processed_data_at = run.use_artifact(f'{params.PROCESSED_DATA_AT}:latest')\n",
    "processed_dataset_dir = Path(processed_data_at.download())\n",
    "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77170345-96d3-4371-a4e9-5ea3b15e2cdb",
   "metadata": {},
   "source": [
    "We will not use the hold out dataset stage at this moment. `is_valid` column will tell our trainer how we want to split data between training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a34e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Stage != 'test'].reset_index(drop=True)  # drop the files corresponding to the test split\n",
    "df['is_valid'] = df.Stage == 'valid'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "346d844c",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10dfa363",
   "metadata": {},
   "source": [
    "Function to get the mask file from the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ae3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname: Path) -> Path:\n",
    "    \"\"\"Generate the path to the mask file corresponding\n",
    "    to the image file in input\n",
    "\n",
    "    Args:\n",
    "        fname (Path): The path to an image file\n",
    "\n",
    "    Returns:\n",
    "        Path: The path to the corresponding mask file\n",
    "    \"\"\"\n",
    "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb25d8-50b0-4c14-9d52-d14725e024c9",
   "metadata": {},
   "source": [
    "We will use `fastai`'s `DataBlock` API to feed data into model training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f713864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign paths to images and labels\n",
    "df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}' for f in df.File_Name.values]\n",
    "df[\"label_fname\"] = [label_func(f) for f in df.image_fname.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4cc4237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Stage</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>image_fname</th>\n",
       "      <th>label_fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a59131a5-00000000.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/images/a59131a5-00000000.jpg</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/labels/a59131a5-00000000_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6886b3d9-6ab2b28d.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/images/6886b3d9-6ab2b28d.jpg</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/labels/6886b3d9-6ab2b28d_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115e4aff-00000000.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/images/115e4aff-00000000.jpg</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/labels/115e4aff-00000000_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b803d91d-671b8cff.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/images/b803d91d-671b8cff.jpg</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/labels/b803d91d-671b8cff_mask.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c665137e-6fffaf45.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/images/c665137e-6fffaf45.jpg</td>\n",
       "      <td>artifacts/bdd_simple_1k_split:v0/labels/c665137e-6fffaf45_mask.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               File_Name  Stage  is_valid  \\\n",
       "0  a59131a5-00000000.jpg  train     False   \n",
       "1  6886b3d9-6ab2b28d.jpg  train     False   \n",
       "2  115e4aff-00000000.jpg  train     False   \n",
       "3  b803d91d-671b8cff.jpg  train     False   \n",
       "4  c665137e-6fffaf45.jpg  train     False   \n",
       "\n",
       "                                                     image_fname  \\\n",
       "0  artifacts/bdd_simple_1k_split:v0/images/a59131a5-00000000.jpg   \n",
       "1  artifacts/bdd_simple_1k_split:v0/images/6886b3d9-6ab2b28d.jpg   \n",
       "2  artifacts/bdd_simple_1k_split:v0/images/115e4aff-00000000.jpg   \n",
       "3  artifacts/bdd_simple_1k_split:v0/images/b803d91d-671b8cff.jpg   \n",
       "4  artifacts/bdd_simple_1k_split:v0/images/c665137e-6fffaf45.jpg   \n",
       "\n",
       "                                                          label_fname  \n",
       "0  artifacts/bdd_simple_1k_split:v0/labels/a59131a5-00000000_mask.png  \n",
       "1  artifacts/bdd_simple_1k_split:v0/labels/6886b3d9-6ab2b28d_mask.png  \n",
       "2  artifacts/bdd_simple_1k_split:v0/labels/115e4aff-00000000_mask.png  \n",
       "3  artifacts/bdd_simple_1k_split:v0/labels/b803d91d-671b8cff_mask.png  \n",
       "4  artifacts/bdd_simple_1k_split:v0/labels/c665137e-6fffaf45_mask.png  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4268334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    df: pd.DataFrame, bs: int = 4, img_size: tuple = (180, 320), augment: bool = True\n",
    ") -> DataLoaders:\n",
    "    \"\"\"Create the data loaders for images using the fastai DataBlock API\n",
    "    from a dataframe that contains the paths to images and labels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe with the paths to the files to use as data\n",
    "        bs (int, optional): The batch size. Defaults to 4.\n",
    "        img_size (tuple, optional): The image size. Defaults to (180, 320).\n",
    "        augment (bool, optional): If using augmentation transforms. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        DataLoaders: The dataloaders\n",
    "    \"\"\"\n",
    "    block = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),\n",
    "        get_x=ColReader(\"image_fname\"),\n",
    "        get_y=ColReader(\"label_fname\"),\n",
    "        splitter=ColSplitter(),\n",
    "        item_tfms=Resize(img_size),\n",
    "        batch_tfms=aug_transforms() if augment else None,\n",
    "    )\n",
    "    return block.dataloaders(df, bs=bs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f7975-ff29-4692-89b3-7f7596aecb0a",
   "metadata": {},
   "source": [
    "We are using `wandb.config` to track our training hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f214f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24ff47bb",
   "metadata": {},
   "source": [
    "Create our dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58544078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19c23798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.data.core.DataLoaders at 0x176ab8700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2689f393",
   "metadata": {},
   "source": [
    "## Define and train UNet model based on `ResNet18`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d4e69-d8ec-4093-a8e4-0f09b0979887",
   "metadata": {},
   "source": [
    "We will use *intersection over union* metrics: mean across all classes (MIOU) and IOU for each class separately. Our model will be a `unet` based on pretrained `resnet18` backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fd4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enrythebest/miniforge3/envs/mlops-wandb/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/enrythebest/miniforge3/envs/mlops-wandb/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/enrythebest/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce60896428b42099bf8bd871c9be521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(), \\\n",
    "           TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]\n",
    "\n",
    "learn = unet_learner(dls, arch=resnet18, pretrained=config.pretrained, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88d45330-cfc2-44e9-8c0c-5eee417050b1",
   "metadata": {},
   "source": [
    "In `fastai` we already have a callback that integrates tightly with W&B, we only need to pass the `WandbCallback` to the learner and we are ready to go. The callback will log all the useful variables for us. For example, whatever metric we pass to the learner will be tracked by the callback. The `WandbCallback` also accepts a string to identify the model name (useful when trying many models) and the dataset name. The model will be saved as an artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87db7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    SaveModelCallback(monitor='miou'),\n",
    "    WandbCallback(log_preds=False, log_model=True)  # we do not log the predictions automatically. We create a table later\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe3c60-f4af-4e21-874d-13f119d03dd5",
   "metadata": {},
   "source": [
    "Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1846493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>miou</th>\n",
       "      <th>background_iou</th>\n",
       "      <th>road_iou</th>\n",
       "      <th>traffic_light_iou</th>\n",
       "      <th>traffic_sign_iou</th>\n",
       "      <th>person_iou</th>\n",
       "      <th>vehicle_iou</th>\n",
       "      <th>bicycle_iou</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.491318</td>\n",
       "      <td>0.421165</td>\n",
       "      <td>0.251009</td>\n",
       "      <td>0.832042</td>\n",
       "      <td>0.713021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.452435</td>\n",
       "      <td>0.449401</td>\n",
       "      <td>0.247709</td>\n",
       "      <td>0.837002</td>\n",
       "      <td>0.602234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334857</td>\n",
       "      <td>0.291190</td>\n",
       "      <td>0.336765</td>\n",
       "      <td>0.893784</td>\n",
       "      <td>0.792019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329983</td>\n",
       "      <td>0.273721</td>\n",
       "      <td>0.342748</td>\n",
       "      <td>0.899133</td>\n",
       "      <td>0.812429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279289</td>\n",
       "      <td>0.281466</td>\n",
       "      <td>0.346482</td>\n",
       "      <td>0.899616</td>\n",
       "      <td>0.802815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262704</td>\n",
       "      <td>0.272615</td>\n",
       "      <td>0.344906</td>\n",
       "      <td>0.906533</td>\n",
       "      <td>0.829176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.225060</td>\n",
       "      <td>0.237343</td>\n",
       "      <td>0.356790</td>\n",
       "      <td>0.915882</td>\n",
       "      <td>0.831107</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.208304</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>0.358016</td>\n",
       "      <td>0.916856</td>\n",
       "      <td>0.835043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.191530</td>\n",
       "      <td>0.231745</td>\n",
       "      <td>0.373429</td>\n",
       "      <td>0.921806</td>\n",
       "      <td>0.843662</td>\n",
       "      <td>0.090874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180440</td>\n",
       "      <td>0.225847</td>\n",
       "      <td>0.371104</td>\n",
       "      <td>0.922678</td>\n",
       "      <td>0.843015</td>\n",
       "      <td>0.066249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>04:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(config.epochs, config.lr, cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ac11f-ad6c-4f9d-b2b0-6acb8d7af34a",
   "metadata": {},
   "source": [
    "We will log a table with model predictions and ground truth to W&B, so that we can do error analysis in the W&B dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "387dc2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [100/100 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples, outputs, predictions = get_predictions(learn)\n",
    "table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
    "wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913a7ca-1250-4a61-a011-d333110bb927",
   "metadata": {},
   "source": [
    "We are reloading the model from the best checkpoint at the end and saving it. To make sure we track the final metrics correctly, we will validate the model again and save the final loss and metrics to `wandb.summary`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ec120e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = learn.validate()\n",
    "metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]\n",
    "final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
    "for k,v in final_results.items(): \n",
    "    wandb.summary[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f86720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47482c1199d47699217aca18f28fdcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='126.570 MB of 126.570 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>background_iou</td><td>▁▁▆▆▆▇▇███</td></tr><tr><td>bicycle_iou</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▂▂▃▄▅▆▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>lr_1</td><td>▁▂▂▃▄▅▆▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>lr_2</td><td>▁▂▂▃▄▅▆▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>miou</td><td>▁▁▆▆▆▆▇▇██</td></tr><tr><td>mom_0</td><td>██▇▆▅▄▃▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>mom_1</td><td>██▇▆▅▄▃▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>mom_2</td><td>██▇▆▅▄▃▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>person_iou</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>█▆▃▃▃▃▃▃▃▃▃▃▂▂▄▃▁▂▂▂▁▂▂▂▂▂▂▁▁▁▂▂▂▂▁▁▁▁▂▁</td></tr><tr><td>road_iou</td><td>▄▁▇▇▇█████</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>traffic_light_iou</td><td>▁▁▁▁▁▁▁▁█▆</td></tr><tr><td>traffic_sign_iou</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_samples_per_sec</td><td>▁█▇▁▆▅▅▆▅▅▃▄▇▆▆▅▇▆▆▇▇▆▆▆▆█▇█▅▇▄▃▃▇██████</td></tr><tr><td>valid_loss</td><td>▇█▃▂▃▂▁▁▁▁</td></tr><tr><td>vehicle_iou</td><td>▁▂▇▇▇▇████</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_2</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>background_iou</td><td>0.92268</td></tr><tr><td>bicycle_iou</td><td>0.0</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>eps_1</td><td>1e-05</td></tr><tr><td>eps_2</td><td>1e-05</td></tr><tr><td>final_background_iou</td><td>0.92181</td></tr><tr><td>final_bicycle_iou</td><td>0.0</td></tr><tr><td>final_loss</td><td>0.23175</td></tr><tr><td>final_miou</td><td>0.37343</td></tr><tr><td>final_person_iou</td><td>0.0</td></tr><tr><td>final_road_iou</td><td>0.84366</td></tr><tr><td>final_traffic_light_iou</td><td>0.09087</td></tr><tr><td>final_traffic_sign_iou</td><td>0.0</td></tr><tr><td>final_vehicle_iou</td><td>0.75766</td></tr><tr><td>lr_0</td><td>0.0</td></tr><tr><td>lr_1</td><td>0.0</td></tr><tr><td>lr_2</td><td>0.0</td></tr><tr><td>miou</td><td>0.3711</td></tr><tr><td>mom_0</td><td>0.95</td></tr><tr><td>mom_1</td><td>0.95</td></tr><tr><td>mom_2</td><td>0.95</td></tr><tr><td>person_iou</td><td>0.0</td></tr><tr><td>raw_loss</td><td>0.1586</td></tr><tr><td>road_iou</td><td>0.84302</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>sqr_mom_1</td><td>0.99</td></tr><tr><td>sqr_mom_2</td><td>0.99</td></tr><tr><td>traffic_light_iou</td><td>0.06625</td></tr><tr><td>traffic_sign_iou</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.18044</td></tr><tr><td>train_samples_per_sec</td><td>3.3465</td></tr><tr><td>valid_loss</td><td>0.22585</td></tr><tr><td>vehicle_iou</td><td>0.76578</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>wd_1</td><td>0.01</td></tr><tr><td>wd_2</td><td>0.01</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">beaming-sweetheart-3</strong> at: <a href='https://wandb.ai/erinaldi-team/mlops-course-001/runs/dz5gabr2' target=\"_blank\">https://wandb.ai/erinaldi-team/mlops-course-001/runs/dz5gabr2</a><br/>Synced 6 W&B file(s), 1 media file(s), 303 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230215_170600-dz5gabr2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-wandb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4cc09e5f9b95d4bcc88fc42952568d46d5e5c9883592c2e6e890264114f7f170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
